{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with CSV Files\n",
    "\n",
    "Welcome back! Let's discuss how to work with CSV files in Python. A file with the CSV file extension is a Comma Separated Values file. All CSV files are plain text, contain alphanumeric characters, and structure the data contained within them in a tabular form. Don't confuse Excel Files with csv files, while csv files are formatted very similarly to excel files, they don't have data types for their values, they are all strings with no font or color. They also don't have worksheets the way an excel file does. Python does have several libraries for working with Excel files, you can check them out [here](http://www.python-excel.org/) and [here](https://www.xlwings.org/).\n",
    "\n",
    "Files in the CSV format are generally used to exchange data, usually when there's a large amount, between different applications. Database programs, analytical software, and other applications that store massive amounts of information (like contacts and customer data), will usually support the CSV format.\n",
    "\n",
    "Let's explore how we can open a csv file with Python's built-in csv library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Notebook Location. \n",
    "\n",
    "Run **pwd** inside a notebook cell to find out where your notebook is located"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:27.555042Z",
     "start_time": "2025-08-17T02:38:27.549993Z"
    }
   },
   "source": [
    "pwd"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\GitCodeBase\\\\python-features-2025\\\\python-bootcamp-projects\\\\projects\\\\03-PDFs & Spreadsheets'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Reading CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:52.606626Z",
     "start_time": "2025-08-17T02:38:52.603207Z"
    }
   },
   "source": [
    "import csv"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing in the file path, make sure to include the extension if it has one, you should be able to Tab Autocomplete the file name. If you can't Tab autocomplete, that is a good indicator your file is not in the same location as your notebook. You can always type in the entire file path (it will look similar in formatting to the output of **pwd**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:36.166739Z",
     "start_time": "2025-08-17T02:38:36.163206Z"
    }
   },
   "source": [
    "data = open('example.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:37.549096Z",
     "start_time": "2025-08-17T02:38:37.545148Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='example.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "Often csv files may contain characters that you can't interpret with standard python, this could be something like an **@** symbol, or even foreign characters. Let's view an example of this sort of error ([its pretty common, so its important to go over](https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character))."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:54.376512Z",
     "start_time": "2025-08-17T02:38:54.373611Z"
    }
   },
   "source": [
    "csv_data = csv.reader(data)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast to a list may give an error, note the **can't decode** line in the error, this is a giveaway that we have an encoding problem!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:38:58.716140Z",
     "start_time": "2025-08-17T02:38:58.683489Z"
    }
   },
   "source": [
    "data_lines = list(csv_data)"
   ],
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 1810: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnicodeDecodeError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m data_lines = \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcsv_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1252.py:23\u001B[39m, in \u001B[36mIncrementalDecoder.decode\u001B[39m\u001B[34m(self, input, final)\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcodecs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcharmap_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdecoding_table\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mUnicodeDecodeError\u001B[39m: 'charmap' codec can't decode byte 0x8d in position 1810: character maps to <undefined>"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not try reading it with a \"utf-8\" encoding."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-08-17T02:39:02.926710Z",
     "start_time": "2025-08-17T02:39:02.922913Z"
    }
   },
   "source": [
    "data = open('example.csv',encoding=\"utf-8\")\n",
    "csv_data = csv.reader(data)\n",
    "data_lines = list(csv_data)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:39:04.359533Z",
     "start_time": "2025-08-17T02:39:04.354793Z"
    }
   },
   "source": [
    "# Looks like it worked!\n",
    "data_lines[:3]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city'],\n",
       " ['1',\n",
       "  'Joseph',\n",
       "  'Zaniolini',\n",
       "  'jzaniolini0@simplemachines.org',\n",
       "  'Male',\n",
       "  '163.168.68.132',\n",
       "  'Pedro Leopoldo'],\n",
       " ['2',\n",
       "  'Freida',\n",
       "  'Drillingcourt',\n",
       "  'fdrillingcourt1@umich.edu',\n",
       "  'Female',\n",
       "  '97.212.102.79',\n",
       "  'Buri']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the first item in the list is the header line, this contains the information about what each column represents. Let's format our printing just a bit:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:39:07.580195Z",
     "start_time": "2025-08-17T02:39:07.577603Z"
    }
   },
   "source": [
    "for line in data_lines[:5]:\n",
    "    print(line)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city']\n",
      "['1', 'Joseph', 'Zaniolini', 'jzaniolini0@simplemachines.org', 'Male', '163.168.68.132', 'Pedro Leopoldo']\n",
      "['2', 'Freida', 'Drillingcourt', 'fdrillingcourt1@umich.edu', 'Female', '97.212.102.79', 'Buri']\n",
      "['3', 'Nanni', 'Herity', 'nherity2@statcounter.com', 'Female', '145.151.178.98', 'Claver']\n",
      "['4', 'Orazio', 'Frayling', 'ofrayling3@economist.com', 'Male', '25.199.143.143', 'Kungur']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we wanted a list of  all the emails. For demonstration, since there are 1000 items plus the header, we will only do a few rows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T02:39:10.753412Z",
     "start_time": "2025-08-17T02:39:10.749811Z"
    }
   },
   "source": [
    "len(data_lines)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-08-17T02:39:12.922941Z",
     "start_time": "2025-08-17T02:39:12.920232Z"
    }
   },
   "source": [
    "all_emails = []\n",
    "for line in data_lines[1:15]:\n",
    "    all_emails.append(line[3])"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jzaniolini0@simplemachines.org', 'fdrillingcourt1@umich.edu', 'nherity2@statcounter.com', 'ofrayling3@economist.com', 'jmurrison4@cbslocal.com', 'lgamet5@list-manage.com', 'dhowatt6@amazon.com', 'kherion7@amazon.com', 'chedworth8@china.com.cn', 'hgasquoine9@google.ru', 'ftarra@shareasale.com', 'abathb@umn.edu', 'lchastangc@goo.gl', 'cceried@yale.edu']\n"
     ]
    }
   ],
   "source": [
    "print(all_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted a list of full names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "full_names = []\n",
    "\n",
    "for line in data_lines[1:15]:\n",
    "    full_names.append(line[1]+' '+line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joseph Zaniolini',\n",
       " 'Freida Drillingcourt',\n",
       " 'Nanni Herity',\n",
       " 'Orazio Frayling',\n",
       " 'Julianne Murrison',\n",
       " 'Lucy Gamet',\n",
       " 'Dyana Howatt',\n",
       " 'Kassey Herion',\n",
       " 'Chrissy Hedworth',\n",
       " 'Hyatt Gasquoine',\n",
       " 'Felicdad Tarr',\n",
       " 'Andrew Bath',\n",
       " 'Lucais Chastang',\n",
       " 'Car Cerie']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to CSV Files\n",
    "\n",
    "We can also write csv files, either new ones or add on to existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New File \n",
    "**This will also overwrite any exisiting file with the same name, so be careful with this!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# newline controls how universal newlines works (it only applies to text\n",
    "# mode). It can be None, '', '\\n', '\\r', and '\\r\\n'. \n",
    "file_to_output = open('to_save_file.csv','w',newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "csv_writer = csv.writer(file_to_output,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_writer.writerow(['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "csv_writer.writerows([['1','2','3'],['4','5','6']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_to_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Existing File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = open('to_save_file.csv','a',newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "csv_writer = csv.writer(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_writer.writerow(['new','new','new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for the basics! If you believe you will be working with CSV files often, you may want to check out the powerful [pandas library](https://pandas.pydata.org/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
